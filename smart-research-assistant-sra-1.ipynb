{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üìò SECTION 0 ‚Äî Header & Licensing (ADK Style)","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:47:55.969840Z","iopub.execute_input":"2025-12-01T14:47:55.970114Z","iopub.status.idle":"2025-12-01T14:47:55.976675Z","shell.execute_reply.started":"2025-12-01T14:47:55.970095Z","shell.execute_reply":"2025-12-01T14:47:55.975599Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"<!-- ##### Copyright 2025 Google LLC. -->\n\n## üß† Smart Research Assistant ‚Äî Multi-Agent ADK Project  \n### *A multi-agent system with parallel + sequential agents, custom tools, built-in tools, sessions, memory, and context engineering.*\n\nThis notebook implements a **complete multi-agent system** using the  \n**Google Agent Development Kit (ADK)**, following the architectural and coding\npatterns from the official Day-1 ‚Üí Day-5 ADK notebooks.\n\nYou will learn how to:\n\n- Build **LLM-powered agents**  \n- Run agents in **sequential and parallel** workflows  \n- Use **built-in ADK tools** (Google Search, Python Code Execution)  \n- Build **custom FunctionTools**  \n- Manage context with **sessions, memory, and compaction**  \n- Combine agent outputs to generate a structured **research brief** including:  \n  - Topic understanding  \n  - Web findings  \n  - Conceptual explanation  \n  - 5 strong points  \n  - 5 weak points / gaps  \n  - Synthesized final summary  \n\nLet's get started. üöÄ\n","metadata":{}},{"cell_type":"markdown","source":"# üìò SECTION 1 ‚Äî Project Overview\nSmart Research Assistant ‚Äî Multi-Agent ADK System","metadata":{}},{"cell_type":"markdown","source":"## üöÄ Section 1: Project Overview\n\nWelcome to the **Smart Research Assistant**, a fully ADK-compliant multi-agent system\ndesigned to generate high-quality research briefs using:\n\n- **Sequential and parallel agents**  \n- **LLM-powered reasoning**  \n- **Built-in ADK tools** (Google Search, Code Execution)  \n- **Custom FunctionTools** for summarization and structure  \n- **Sessions, memory, and context compaction**  \n- **Structured, JSON-friendly outputs**  \n\n---\n\n### üéØ What this agent system does\n\nGiven a topic such as:\n\n> *\"Sleep disorder detection using multimodal signals\"*\n\nThe system will:\n\n1. **Understand** the user's query  \n2. **Extract keywords** and contextual information  \n3. Run **parallel agents** to:\n   - Search the web for recent findings  \n   - Produce conceptual and theoretical background  \n4. Identify:\n   - **5 strong points** in existing research  \n   - **5 weak points or gaps**  \n5. **Synthesize everything** into a structured, well-organized research brief  \n\n---\n\n### üß© Key Features You Will Implement\n\n- **Multi-agent architecture**  \n  - Query Understanding Agent  \n  - Web Research Agent (parallel)  \n  - Knowledge Explainer Agent (parallel)  \n  - Strength‚ÄìWeakness Analyzer  \n  - Final Synthesizer Agent  \n\n- **Parallel execution** with `asyncio.gather`  \n- **Sessions & Memory**  \n  - Persistent conversation context  \n  - State tracking  \n  - Memory over multiple calls  \n\n- **Context Engineering**\n  - Context compaction  \n  - Summaries for long contexts  \n  - Relevance-based memory filtering  \n\n- **Tools**\n  - Google Search Tool  \n  - Python Code Execution Tool  \n  - Custom FunctionTools (keyword extractor, bullet formatter, etc.)  \n\n---\n\n### üß± How this notebook is structured\n\nThis notebook follows the **same instructional design style as the ADK daily notebooks**:\n\n1. Setup  \n2. Architecture diagram  \n3. Sessions & memory  \n4. Tools  \n5. Agents  \n6. Root Orchestrator  \n7. Runner  \n8. Demo  \n9. Appendix  \n\nEach section is implemented with:\n- Configuration cells  \n- Code blocks  \n- Explanatory Markdown  \n- ADK-style comments and structure  \n\n---\n\n### üéâ By the end of this notebook\n\nYou will have a *fully functional*, *deployable*, *extensible*  \n**multi-agent research assistant** built with the Google ADK.\n\nLet's move to the setup.\n","metadata":{}},{"cell_type":"markdown","source":"# üìò SECTION 2 ‚Äî Setup\nInstall dependencies, import libraries, configure API keys, and set core settings.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 2: Setup\n\nIn this section, we will:\n\n1. Install the necessary dependencies  \n2. Import ADK and Python libraries  \n3. Configure your Gemini API Key  \n4. Set up model and retry configurations  \n5. Define notebook-level constants  \n\nThese steps follow the same environment initialization pattern used\nthroughout the official ADK Day 1‚Äì5 notebooks.\n","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Install Dependencies","metadata":{}},{"cell_type":"code","source":"# # @title Install dependencies\n# # This cell installs the Google Agent Development Kit (ADK) and other required libraries.\n\n# !pip install -q google-generativeai\n# !pip install -q google-adk\n# !pip install -q python-dotenv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:47:56.002145Z","iopub.execute_input":"2025-12-01T14:47:56.002389Z","iopub.status.idle":"2025-12-01T14:47:56.006826Z","shell.execute_reply.started":"2025-12-01T14:47:56.002374Z","shell.execute_reply":"2025-12-01T14:47:56.005800Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### 2.2 Import Libraries","metadata":{}},{"cell_type":"code","source":"# # @title Import core libraries\n\n# import os\n# import json\n# import asyncio\n# from typing import Any, Dict, List\n\n# # ADK components\n# from google.adk.agents import Agent\n# from google.adk.runners import InMemoryRunner\n# from google.adk.sessions import InMemorySessionService\n# from google.adk.tools import FunctionTool, PythonCodeExecutor, GoogleSearchTool\n# from google.adk.types import HttpRetryOptions\n# from google.adk.models import google_llm\n\n\n\n# Core Python Libraries\nimport os\nimport sys\nimport json\nimport random\nimport logging\nimport datetime\nfrom pathlib import Path\nfrom typing import List, Dict, Union, Any, Optional\nfrom pprint import pprint\n\n# Data Handling\nimport pandas as pd\nimport numpy as np\n\n# Kaggle Resources\nfrom kaggle_secrets import UserSecretsClient\n\n# Call synchronisation \nimport asyncio\n\n# Google ADK Modules (Standard Day 1 - Day 5 Patterns)\ntry:\n    import google.adk \n    from google.adk.agents import LlmAgent, Agent, SequentialAgent, ParallelAgent, LoopAgent        \n    from google.adk.models.google_llm import Gemini\n    from google.adk.runners import Runner, InMemoryRunner\n    from google.adk.sessions import InMemorySessionService, DatabaseSessionService #, InMemoryMemoryService \n    from google.adk.memory import InMemoryMemoryService\n    from google.adk.tools import load_memory, preload_memory\n    from google.adk.tools import google_search, FunctionTool, AgentTool, ToolContext, BaseTool \n    from google.adk.tools.tool_context import ToolContext\n    from google.adk.code_executors import BuiltInCodeExecutor\n    from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n    from google.genai import types\n    from google.adk.apps.app import App, ResumabilityConfig, EventsCompactionConfig\n    from google.adk.tools.function_tool import FunctionTool\n    \n    from google.genai import types\n    import google.generativeai as genai\n\n    # A2A / Production Modules (Day 5 Pattern)\n    from google.adk.agents.remote_a2a_agent import RemoteA2aAgent, AGENT_CARD_WELL_KNOWN_PATH\n    from google.adk.a2a.utils.agent_to_a2a import to_a2a\n\n    print(f\"google.adk.__version__: {google.adk.__version__}\")\n    print(f\"google.adk.__file__: {google.adk.__file__}\")\n    print(\"‚úÖ Google ADK libraries imported successfully.\")\n\nexcept ImportError as e:\n    print(\"‚ùå Error importing Google ADK. Please ensure the environment is configured correctly.\")\n    print(f\"Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:47:56.013185Z","iopub.execute_input":"2025-12-01T14:47:56.013554Z","iopub.status.idle":"2025-12-01T14:48:23.255117Z","shell.execute_reply.started":"2025-12-01T14:47:56.013532Z","shell.execute_reply":"2025-12-01T14:48:23.253645Z"}},"outputs":[{"name":"stdout","text":"google.adk.__version__: 1.18.0\ngoogle.adk.__file__: /usr/local/lib/python3.11/dist-packages/google/adk/__init__.py\n‚úÖ Google ADK libraries imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 2.3 Configure Gemini API Key","metadata":{}},{"cell_type":"code","source":"try:\n    # Attempt to retrieve the secret labeled 'GOOGLE_API_KEY'\n    GOOGLE_API_KEY = UserSecretsClient().get_secret('GOOGLE_API_KEY')\n    \n    # Set it as an environment variable for ADK/Gemini to find\n    os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n    \n    print(\"‚úÖ API Key successfully loaded from Kaggle Secrets.\")\n    \nexcept Exception as e:\n    print(\"‚ö†Ô∏è Authentication Warning:\")\n    print(\"   Could not find 'GOOGLE_API_KEY' in Kaggle Secrets.\")\n    print(\"   Please go to 'Add-ons' -> 'Secrets' and add your key.\")\n    print(f\"   Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.257039Z","iopub.execute_input":"2025-12-01T14:48:23.257805Z","iopub.status.idle":"2025-12-01T14:48:23.506963Z","shell.execute_reply.started":"2025-12-01T14:48:23.257782Z","shell.execute_reply":"2025-12-01T14:48:23.506077Z"}},"outputs":[{"name":"stdout","text":"‚úÖ API Key successfully loaded from Kaggle Secrets.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 2.4 Retry Configuration","metadata":{}},{"cell_type":"code","source":"# @title Retry configuration \nretry_config = types.HttpRetryOptions(\n    attempts = 5, \n    exp_base = 2, \n    initial_delay = 1, \n    http_status_codes = [429, 500, 503, 504]\n    )\n\nretry_config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.507650Z","iopub.execute_input":"2025-12-01T14:48:23.507843Z","iopub.status.idle":"2025-12-01T14:48:23.516591Z","shell.execute_reply.started":"2025-12-01T14:48:23.507825Z","shell.execute_reply":"2025-12-01T14:48:23.515641Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"HttpRetryOptions(\n  attempts=5,\n  exp_base=2.0,\n  http_status_codes=[\n    429,\n    500,\n    503,\n    504,\n  ],\n  initial_delay=1.0\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### 2.5 Model Configuration","metadata":{}},{"cell_type":"code","source":"# @title Model configuration\n\n# AGENT_MODEL = \"gemini-2.5-flash-lite\" #\"gemini-2.5-flash\",     # Fast, cost-efficient research model #\"gemini-2.5-flash\" \"gemini-2.5-flash-lite\"\n# MODEL = Gemini(model=AGENT_MODEL)\n\n# if retry_config: \n#     MODEL = Gemini(model=AGENT_MODEL, retry_options=retry_config)\n# else:\n#     MODEL = Gemini(model=AGENT_MODEL)\n\n# MODEL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.518263Z","iopub.execute_input":"2025-12-01T14:48:23.518482Z","iopub.status.idle":"2025-12-01T14:48:23.535829Z","shell.execute_reply.started":"2025-12-01T14:48:23.518461Z","shell.execute_reply":"2025-12-01T14:48:23.534400Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### 2.6 Notebook Constants","metadata":{}},{"cell_type":"code","source":"# @title Notebook constants\n\nMAX_CONTEXT_TURNS = 8            # Maximum turns to keep before compaction\nMAX_HISTORY_KEEP = 3             # Number of recent items preserved during compaction\nSUMMARY_MODEL = \"gemini-2.5-flash\"\n\nprint(\"Setup complete. ADK environment initialized.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.536862Z","iopub.execute_input":"2025-12-01T14:48:23.537185Z","iopub.status.idle":"2025-12-01T14:48:23.561995Z","shell.execute_reply.started":"2025-12-01T14:48:23.537161Z","shell.execute_reply":"2025-12-01T14:48:23.560720Z"}},"outputs":[{"name":"stdout","text":"Setup complete. ADK environment initialized.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# üìò SECTION 3 ‚Äî Project Architecture Overview\nUnderstanding the multi-agent workflow before implementation","metadata":{}},{"cell_type":"markdown","source":"## üß± Section 3: Project Architecture Overview\n\nBefore implementing the agents, tools, memory, and orchestrator,\nit's important to understand **how the Smart Research Assistant works end-to-end**.\n\nThis project uses a **hybrid multi-agent architecture** that combines:\n\n- **Sequential execution** (step-by-step reasoning and synthesis)\n- **Parallel execution** (simultaneous research streams)\n- **LLM-driven agents**\n- **Custom + built-in tools**\n- **Sessions + memory**\n- **Context compaction**\n\nBelow is an overview of the data and control flow.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.1 High-Level Workflow Diagram","metadata":{}},{"cell_type":"code","source":"# üß© Multi-Agent Workflow (Sequential + Parallel)\n\n\"\"\"\nUser Query\n    ‚îÇ\n    ‚ñº\nüìò Query Understanding Agent  (LLM + Memory)\n    - Interprets the topic\n    - Extracts keywords\n    - Reads previous session memory\n    - Produces structured intent JSON\n    ‚îÇ\n    ‚ñº\n===================== PARALLEL EXECUTION =====================\n‚îÇ                                                          ‚îÇ\n‚ñº                                                          ‚ñº\nüîç Web Research Agent                                      üß† Knowledge Explainer Agent\n- Uses Google Search Tool                                 - LLM conceptual explanation\n- Finds recent findings                                   - Expands topics and theory\n- Extracts insights                                       - Summarizes academic context\n‚îÇ                                                          ‚îÇ\n===================== RESULTS MERGE BACK ======================\n    ‚îÇ\n    ‚ñº\nüìä Strength‚ÄìWeakness Agent\n    - Produces 5 strong points\n    - Produces 5 weak points (gaps)\n    - Applies context compaction on parallel outputs\n    ‚îÇ\n    ‚ñº\nüìù Research Synthesizer Agent\n    - Merges all results\n    - Ensures structured final JSON output\n    - Updates session memory\n    ‚îÇ\n    ‚ñº\nüéâ Final Research Brief (JSON + formatted text)\n\"\"\"\n\n\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.563573Z","iopub.execute_input":"2025-12-01T14:48:23.564062Z","iopub.status.idle":"2025-12-01T14:48:23.586330Z","shell.execute_reply.started":"2025-12-01T14:48:23.564026Z","shell.execute_reply":"2025-12-01T14:48:23.585381Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"''"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"### 3.2 Key Architectural Concepts","metadata":{}},{"cell_type":"markdown","source":"### üî∏ Agents (LLM-powered)\nEach agent is a subclass of `Agent` and implements an async `run()` method.\nAgents may:\n- Call tools\n- Perform reasoning\n- Transform or merge results\n- Update memory\n\n### üî∏ Tools\nWe use:\n- Google Search Tool (built-in)\n- Python Code Execution (optional)\n- Custom FunctionTools for:\n  - keyword extraction\n  - summarization\n  - bullet list formatting\n  - gap identification\n\n### üî∏ Sessions & Memory\nSession data persists across calls using:\n\n`InMemorySessionService()`\n\nTo avoid runaway context, we implement:\n\n**context compaction**, where:\n- only the last few turns are kept fully\n- older turns are summarized\n- irrelevant historical content is removed\n\n### üî∏ Parallelism\nTwo agents are run concurrently:\n\n- Web Research Agent  \n- Knowledge Explainer Agent  \n\nusing `asyncio.gather()`.\n\n### üî∏ Final Synthesis\nA final agent merges:\n- web findings\n- theoretical background\n- strengths & weaknesses\ninto a single structured JSON object.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.3 Architecture Summary","metadata":{}},{"cell_type":"markdown","source":"The Smart Research Assistant follows a **progressive refinement workflow**:\n\n1. Understand the query  \n2. Expand the topic using two parallel research paths  \n3. Evaluate strong/weak points  \n4. Compress context  \n5. Produce final structured output  \n\nThis mirrors real academic research workflows and demonstrates\nall ADK concepts required for the Capstone project.\n","metadata":{}},{"cell_type":"markdown","source":"# üìò SECTION 4 ‚Äî Sessions & Memory\nState management, session continuity, and context compaction.","metadata":{}},{"cell_type":"markdown","source":"## üß† Section 4: Sessions & Memory\n\nLarge Language Model (LLM)‚Äìpowered agents work best when they have access to\n**persistent state across multiple turns**. In the Google ADK, this is handled\nthrough a **Session Service** that stores agent inputs, outputs, and custom metadata.\n\nIn this project, sessions enable the Smart Research Assistant to:\n\n- Remember previous queries  \n- Maintain extracted keywords or constraints  \n- Preserve research context  \n- Apply context compaction to avoid runaway prompt growth  \n\nWe will implement:\n\n1. `InMemorySessionService` ‚Äî ADK's built-in lightweight session layer  \n2. A custom `MemoryManager` ‚Äî handles saving, retrieving, and compacting memory  \n3. Context compaction rules ‚Äî mirrors Day-3B‚Äôs pattern  \n","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Session Service Initialization","metadata":{}},{"cell_type":"code","source":"# @title Initialize Session Service\n\n# The session service stores conversation-level state that persists across calls.\nsession_service = InMemorySessionService()\n\nprint(\"Session service initialized.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.587216Z","iopub.execute_input":"2025-12-01T14:48:23.587396Z","iopub.status.idle":"2025-12-01T14:48:23.605084Z","shell.execute_reply.started":"2025-12-01T14:48:23.587381Z","shell.execute_reply":"2025-12-01T14:48:23.603763Z"}},"outputs":[{"name":"stdout","text":"Session service initialized.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### 4.2 MemoryManager Class\n\nThis class mirrors the design philosophy of the ADK Day-3B ‚ÄúAgent Memory‚Äù notebook, including:\n\n- Turn-based memory items\n\n- Summarization of older history\n\n- Keeping only the most relevant parts\n\n- Optional compaction triggers","metadata":{}},{"cell_type":"code","source":"# @title Memory Manager Implementation\n\nclass MemoryManager:\n    \"\"\"\n    Handles storage and compaction of memory for each session.\n\n    The memory structure mirrors best practices from the ADK Day-3 notebooks:\n    - Keep recent turns fully\n    - Summarize older turns\n    - Remove irrelevant or low-value content\n    \"\"\"\n\n    def __init__(self, max_turns=MAX_CONTEXT_TURNS, keep_last=MAX_HISTORY_KEEP):\n        self.max_turns = max_turns\n        self.keep_last = keep_last\n\n    def load(self, session_state: dict) -> List[dict]:\n        \"\"\"Retrieve memory list from session state.\"\"\"\n        return session_state.get(\"memory\", [])\n\n    def save(self, session_state: dict, memory: List[dict]):\n        \"\"\"Persist updated memory back to the session.\"\"\"\n        session_state[\"memory\"] = memory\n\n    async def compact(self, memory: List[dict], llm_model) -> List[dict]:\n        \"\"\"\n        Apply context compaction:\n        - If memory is short, return as-is\n        - If it exceeds max_turns, summarize older items using an LLM\n        \"\"\"\n        if len(memory) <= self.max_turns:\n            return memory\n\n        # Step 1: Keep the last N items unchanged\n        recent_items = memory[-self.keep_last:]\n\n        # Step 2: Summarize older items\n        old_items = memory[:-self.keep_last]\n        old_text = \"\\n\".join([item[\"content\"] for item in old_items])\n\n        summary_prompt = (\n            \"Summarize the following conversation history into a concise \"\n            \"set of key points that preserve meaning but remove redundancy:\\n\\n\"\n            f\"{old_text}\"\n        )\n\n        summary = await llm_model(summary_prompt)\n\n        # Step 3: Replace old items with a single summary item\n        compacted = [{\"type\": \"summary\", \"content\": summary}] + recent_items\n\n        return compacted\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.606169Z","iopub.execute_input":"2025-12-01T14:48:23.606350Z","iopub.status.idle":"2025-12-01T14:48:23.635263Z","shell.execute_reply.started":"2025-12-01T14:48:23.606337Z","shell.execute_reply":"2025-12-01T14:48:23.633478Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### 4.3 Helper Functions for Memory Operations\n\nThese helpers mimic patterns in ADK notebooks:\nclean, readable, and explicitly tied to the session state.","metadata":{}},{"cell_type":"code","source":"# @title Memory helper functions\n\nasync def load_memory(session_id: str) -> List[dict]:\n    \"\"\"Retrieve memory for a given session.\"\"\"\n    session_state = session_service.get(session_id)\n    memory = memory_manager.load(session_state)\n    return memory\n\n\nasync def save_memory(session_id: str, memory: List[dict]):\n    \"\"\"Save updated memory after compaction or new entries.\"\"\"\n    session_state = session_service.get(session_id)\n    memory_manager.save(session_state, memory)\n    session_service.set(session_id, session_state)\n\n\nasync def add_memory_item(session_id: str, item: dict, llm_model):\n    \"\"\"Add a new item and apply compaction if necessary.\"\"\"\n    memory = await load_memory(session_id)\n    memory.append(item)\n    memory = await memory_manager.compact(memory, llm_model)\n    await save_memory(session_id, memory)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.636708Z","iopub.execute_input":"2025-12-01T14:48:23.636987Z","iopub.status.idle":"2025-12-01T14:48:23.661009Z","shell.execute_reply.started":"2025-12-01T14:48:23.636967Z","shell.execute_reply":"2025-12-01T14:48:23.659896Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### 4.4 Instantiate MemoryManager","metadata":{}},{"cell_type":"code","source":"# @title Instantiate Memory Manager\n\nmemory_manager = MemoryManager(\n    max_turns=MAX_CONTEXT_TURNS,\n    keep_last=MAX_HISTORY_KEEP\n)\n\nprint(\"Memory manager initialized with compaction rules:\")\nprint(f\"- Max turns: {MAX_CONTEXT_TURNS}\")\nprint(f\"- Keep last: {MAX_HISTORY_KEEP}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.663776Z","iopub.execute_input":"2025-12-01T14:48:23.664026Z","iopub.status.idle":"2025-12-01T14:48:23.690910Z","shell.execute_reply.started":"2025-12-01T14:48:23.664006Z","shell.execute_reply":"2025-12-01T14:48:23.690138Z"}},"outputs":[{"name":"stdout","text":"Memory manager initialized with compaction rules:\n- Max turns: 8\n- Keep last: 3\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"\n### 4.5: Helper functions\n\nThis helper function manages a complete conversation session, handling session creation/retrieval, query processing, and response streaming.\n","metadata":{"execution":{"iopub.status.busy":"2025-12-01T14:23:53.327865Z","iopub.execute_input":"2025-12-01T14:23:53.328201Z","iopub.status.idle":"2025-12-01T14:23:53.335309Z","shell.execute_reply.started":"2025-12-01T14:23:53.328178Z","shell.execute_reply":"2025-12-01T14:23:53.333623Z"}}},{"cell_type":"code","source":"# @helper function for running session \n\nasync def run_session(\n    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n):\n    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n    print(f\"\\n### Session: {session_id}\")\n\n    # Create or retrieve session\n    try:\n        session = await session_service.create_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n        )\n\n    # Convert single query to list\n    if isinstance(user_queries, str):\n        user_queries = [user_queries]\n\n    # Process each query\n    for query in user_queries:\n        print(f\"\\nUser > {query}\")\n        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n\n        # Stream agent response\n        async for event in runner_instance.run_async(\n            user_id=USER_ID, session_id=session.id, new_message=query_content\n        ):\n            if event.is_final_response() and event.content and event.content.parts:\n                text = event.content.parts[0].text\n                if text and text != \"None\":\n                    print(f\"Model: > {text}\")\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.691656Z","iopub.execute_input":"2025-12-01T14:48:23.691858Z","iopub.status.idle":"2025-12-01T14:48:23.717571Z","shell.execute_reply.started":"2025-12-01T14:48:23.691839Z","shell.execute_reply":"2025-12-01T14:48:23.715966Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# üìò SECTION 5 ‚Äî Tools Setup\nBuilt-in tools + custom FunctionTools for research analysis","metadata":{}},{"cell_type":"markdown","source":"## üîß Section 5: Tools Setup\n\nAgents in ADK become far more capable when they can call tools.\n\nIn this project, tools enable:\n- Web research (Google Search)\n- Text summarization\n- Keyword extraction\n- Strength/weakness detection\n- Bullet formatting\n- JSON cleaning\n\nFollowing ADK best practices (Day-2 notebooks):\n- Tools should be **stateless**\n- Tools should be **atomic** (do one thing well)\n- Tools should return **dict-like outputs**\n- Tools should declare name + description for LLM routing\n","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Google Search Tool (Built-in)\n\ngoogle_search built-in tool to be Used by the Web Research Agent.","metadata":{}},{"cell_type":"code","source":"# # @title Google Search Tool\n\n# def google_search_agent_tool(gsa_name, gsa_instruction): \n#     google_search_tool = Agent(\n#         name=gsa_name,\n#         model=Gemini(model=SUMMARY_MODEL, retry_options=retry_config),\n#         instruction=gsa_instruction,\n#         tools=[google_search],     # ‚Üê This is the tool\n#     )\n#     return google_search_tool\n\n# print(\"Google Search Tool initialized.\")\n\n\n# # @agent Agent for Google search\n\n# researcher_economic = google_search_agent_tool(gsa_name=\"ResearcherEconomic\", gsa_instruction=\"\"\" You are an expert reseracher that searches on internet (google_search tool) for specific research topic. \n# You read first 10 papers to find out the summary, research findings, strong points from the findings and research gaps. \n# After google search read each paper (if freely available on internet or else read the abstract only) in details to find out the above information and summarise them. \n# You must read the paper as a positive reader focusing mainly from financial and application perspective. \n# \"\"\") \n\n# researcher_technical = google_search_agent_tool(gsa_name=\"ResearcherTechnical\", gsa_instruction=\"\"\" You are an expert reseracher that searches on internet (google_search tool) for specific research topic. \n# You read first 15 papers to find out the summary, research findings, strong points from the findings and research gaps. \n# After google search read each paper (if freely available on internet or else read the abstract only) in details to find out the above information and summarise them. \n# You must read the paper as a positive reader focusing mainly from technical and information technology perspective. \n# \"\"\") \n\n# researcher_economic, researcher_technical \n\n\n# @title Google Search Tool \nSEARCH_TOOL = google_search \n\nSEARCH_TOOL\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.718626Z","iopub.execute_input":"2025-12-01T14:48:23.718909Z","iopub.status.idle":"2025-12-01T14:48:23.753355Z","shell.execute_reply.started":"2025-12-01T14:48:23.718889Z","shell.execute_reply":"2025-12-01T14:48:23.752101Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<google.adk.tools.google_search_tool.GoogleSearchTool at 0x7ccf698ecbd0>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### 5.2 Keyword Extraction Tool (FunctionTool)\n\nMatches ADK practice: small, stateless, atomic.","metadata":{}},{"cell_type":"code","source":"# @title Keyword Extraction Tool\n\ndef extract_keywords(text: str) -> dict:\n    \"\"\"\n    A simple heuristic keyword extractor.\n    ADK best practices recommend atomic, deterministic tools.\n    \"\"\"\n    words = [w.strip(\".,()\") for w in text.lower().split()]\n    stopwords = {\"the\",\"and\",\"or\",\"to\",\"a\",\"is\",\"in\",\"of\",\"for\",\"on\",\"with\",\"using\"}\n    keywords = [w for w in words if w not in stopwords and len(w) > 4]\n    keywords = list(set(keywords))  # ensure uniqueness\n    return {\"keywords\": keywords}\n\nprint(\"Keyword Extraction Tool initialized.\")\n\n\nkeyword_tool = FunctionTool(\n    # name=\"extract_keywords\",\n    # description=\"Extracts keywords from input text using simple heuristics.\",\n    func=extract_keywords,\n)\n\nkeyword_tool\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.754252Z","iopub.execute_input":"2025-12-01T14:48:23.754474Z","iopub.status.idle":"2025-12-01T14:48:23.791278Z","shell.execute_reply.started":"2025-12-01T14:48:23.754457Z","shell.execute_reply":"2025-12-01T14:48:23.789684Z"}},"outputs":[{"name":"stdout","text":"Keyword Extraction Tool initialized.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<google.adk.tools.function_tool.FunctionTool at 0x7ccf67962910>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### 5.3 Bullet List Formatting Tool (FunctionTool)\n\nUsed later by the Strength‚ÄìWeakness Agent.","metadata":{}},{"cell_type":"code","source":"# @title Bullet List Formatting Tool\n\ndef bullet_format(items: list) -> dict:\n    \"\"\"\n    Format a list of items as clean bullet points.\n    \"\"\"\n    formatted = \"\\n\".join([f\"- {item}\" for item in items])\n    return {\"bullets\": formatted}\n\nprint(\"Bullet Formatting Tool initialized.\")\n\nbullet_tool = FunctionTool(\n    # name=\"bullet_format\",\n    # description=\"Formats a list of strings into Markdown-style bullet points.\",\n    func=bullet_format,\n)\n\nbullet_tool \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.792587Z","iopub.execute_input":"2025-12-01T14:48:23.793534Z","iopub.status.idle":"2025-12-01T14:48:23.826402Z","shell.execute_reply.started":"2025-12-01T14:48:23.793486Z","shell.execute_reply":"2025-12-01T14:48:23.824066Z"}},"outputs":[{"name":"stdout","text":"Bullet Formatting Tool initialized.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<google.adk.tools.function_tool.FunctionTool at 0x7ccf679895d0>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### 5.4 Strength/Weakness Heuristic Extraction Tool (FunctionTool)\n\nThis tool is used before LLM refinement ‚Äî exactly like Day-2B‚Äôs pattern of\n‚Äúweak heuristic ‚Üí LLM agent for refinement‚Äù.","metadata":{}},{"cell_type":"code","source":"# @title Strength/Weakness Extraction Tool\n\ndef extract_strengths_weaknesses(text: str) -> dict:\n    \"\"\"\n    Heuristic extraction of candidate strengths and weaknesses.\n    The LLM agent will refine these later.\n    \"\"\"\n    sentences = [s.strip() for s in text.split(\".\") if len(s.strip()) > 8]\n\n    strengths = sentences[:5] if len(sentences) >= 5 else sentences\n    weaknesses = sentences[-5:] if len(sentences) >= 5 else sentences\n\n    return {\n        \"strengths\": strengths,\n        \"weaknesses\": weaknesses,\n    }\n\nprint(\"Strength/Weakness Tool initialized.\")\n\nstrength_gap_tool = FunctionTool(\n    # name=\"extract_strengths_weaknesses\",\n    # description=\"Extracts candidate strengths and weaknesses from raw text.\",\n    func=extract_strengths_weaknesses,\n)\n\nstrength_gap_tool \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.827798Z","iopub.execute_input":"2025-12-01T14:48:23.828095Z","iopub.status.idle":"2025-12-01T14:48:23.857278Z","shell.execute_reply.started":"2025-12-01T14:48:23.828074Z","shell.execute_reply":"2025-12-01T14:48:23.855350Z"}},"outputs":[{"name":"stdout","text":"Strength/Weakness Tool initialized.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<google.adk.tools.function_tool.FunctionTool at 0x7ccf85b82e90>"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### 5.5 Tool Registry (ADK Style)\n\nThis is exactly like the pattern used in Day-2 notebooks:\nCentralize tools so that root agents can inject them.","metadata":{}},{"cell_type":"code","source":"# @title Tool Registry\n\nTOOLS = {\n    \"web_search\": SEARCH_TOOL,               # ADK-provided google_search tool\n    \"extract_keywords\": keyword_tool,\n    \"bullet_format\": bullet_tool,\n    \"strength_gap_tool\": strength_gap_tool,\n}\n\nTOOLS\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.859105Z","iopub.execute_input":"2025-12-01T14:48:23.859526Z","iopub.status.idle":"2025-12-01T14:48:23.879866Z","shell.execute_reply.started":"2025-12-01T14:48:23.859460Z","shell.execute_reply":"2025-12-01T14:48:23.877681Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'web_search': <google.adk.tools.google_search_tool.GoogleSearchTool at 0x7ccf698ecbd0>,\n 'extract_keywords': <google.adk.tools.function_tool.FunctionTool at 0x7ccf67962910>,\n 'bullet_format': <google.adk.tools.function_tool.FunctionTool at 0x7ccf679895d0>,\n 'strength_gap_tool': <google.adk.tools.function_tool.FunctionTool at 0x7ccf85b82e90>}"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# üìò SECTION 6 ‚Äî Agent Implementations\nLLM-powered agents for a sequential + parallel workflow","metadata":{}},{"cell_type":"markdown","source":"## ü§ñ Section 6: Agent Implementations\n\nWe now define all LLM-powered agents used in the Smart Research Assistant.\n\nEach agent follows the ADK agent pattern:\n\n- Uses a `Gemini` model\n- Has a clear instruction block\n- Returns structured JSON-like dicts\n- May call tools (e.g., web_search)\n- May use memory/context to refine behavior\n- Implements `async run()` as recommended in ADK tutorials\n\nWe implement 5 agents:\n\n1. Query Understanding Agent  \n2. Web Research Agent (parallel)  \n3. Knowledge Explainer Agent (parallel)  \n4. Strength‚ÄìWeakness Agent  \n5. Research Synthesizer Agent  \n","metadata":{}},{"cell_type":"markdown","source":"### 6.1 Query Understanding Agent\n\nExtracts topic, keywords, and relevant memory.\n\nThis one does not use tools.\nIt uses LLM reasoning + memory input.","metadata":{}},{"cell_type":"code","source":"# @title QueryUnderstandingAgent\n\nclass QueryUnderstandingAgent(Agent):\n    def __init__(self, model):\n        super().__init__(\n            name=\"QueryUnderstandingAgent\",\n            model=model,\n            instruction=\"\"\"\nYou are a Query Understanding Agent.\n\nYour goals:\n1. Interpret the user's research question clearly.\n2. Extract the core topic.\n3. Identify relevant keywords.\n4. Incorporate prior session memory summaries (if available).\n5. Produce structured JSON output with:\n   - topic\n   - keywords\n   - context_summary\n\"\"\",\n            output_key=\"query_understanding\",\n        )\n\n    async def run(self, user_query: str, memory_summary: str = \"\"):\n        prompt = f\"\"\"\nUSER QUERY:\n{user_query}\n\nMEMORY SUMMARY:\n{memory_summary}\n\nTASK:\nReturn a JSON object with:\n- \"topic\": short topic description\n- \"keywords\": list of important terms\n- \"context_summary\": 1‚Äì2 sentence overall interpretation\n\"\"\"\n        response = await self.model(prompt)\n        return {\"topic\": user_query, \"analysis\": response}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.881352Z","iopub.execute_input":"2025-12-01T14:48:23.882390Z","iopub.status.idle":"2025-12-01T14:48:23.928088Z","shell.execute_reply.started":"2025-12-01T14:48:23.882302Z","shell.execute_reply":"2025-12-01T14:48:23.926830Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### 6.2 Web Research Agent (Parallel Agent #1)\n\nUses google_search to retrieve external info.\n\nThis matches the pattern used in the Day-1B example where they define:\n\ntools=[google_search]\n\nüåü Important: we wrap the results using ADK's AgentTool pattern only when chaining agents, but here we call the tool directly inside run().","metadata":{}},{"cell_type":"code","source":"# @title WebResearchAgent\n\nclass WebResearchAgent(Agent):\n    def __init__(self, model, search_tool):\n        super().__init__(\n            name=\"WebResearchAgent\",\n            model=model,\n            instruction=\"\"\"\nYou are a Web Research Agent.\n\nUse the `search tool` tool to gather:\n- recent findings\n- related topics\n- short descriptions\n- high-level insights\n\nReturn structured bullet points summarizing what you find.\n\"\"\",\n            tools=[search_tool],\n            output_key=\"web_research\",\n        )\n\n    async def run(self, topic: str):\n        # The ADK google_search tool expects a dict input\n        search_results = await self.tools[\"web_search\"].call({\"query\": topic})\n\n        prompt = f\"\"\"\nSummarize the following search results into 5‚Äì7 concise points:\n\n{search_results}\n\"\"\"\n        summary = await self.model(prompt)\n        return {\"web_findings\": summary}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.929027Z","iopub.execute_input":"2025-12-01T14:48:23.929219Z","iopub.status.idle":"2025-12-01T14:48:23.965374Z","shell.execute_reply.started":"2025-12-01T14:48:23.929205Z","shell.execute_reply":"2025-12-01T14:48:23.964066Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### 6.3 Knowledge Explainer Agent (Parallel Agent #2)\n\nProvides conceptual, theoretical background.","metadata":{}},{"cell_type":"code","source":"# @title KnowledgeExplainerAgent\n\nclass KnowledgeExplainerAgent(Agent):\n    def __init__(self, model):\n        super().__init__(\n            name=\"KnowledgeExplainerAgent\",\n            model=model,\n            instruction=\"\"\"\nYou are a Knowledge Explainer Agent.\n\nYour job:\n- Expand and clarify the topic.\n- Provide conceptual, theoretical, or domain-specific insights.\n- Assume the reader is familiar with research-level language.\n- Return 2‚Äì4 short paragraphs of explanation.\n\"\"\",\n            output_key=\"concept_explanation\",\n        )\n\n    async def run(self, topic: str):\n        prompt = f\"\"\"\nExplain the topic below in 2‚Äì4 short paragraphs:\n\nTOPIC: {topic}\n\nKeep it factual and academically neutral.\n\"\"\"\n        explanation = await self.model(prompt)\n        return {\"conceptual_background\": explanation}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:23.966814Z","iopub.execute_input":"2025-12-01T14:48:23.967119Z","iopub.status.idle":"2025-12-01T14:48:24.006405Z","shell.execute_reply.started":"2025-12-01T14:48:23.967098Z","shell.execute_reply":"2025-12-01T14:48:24.005193Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### 6.4 Strength‚ÄìWeakness Agent\n\nUses heuristic FunctionTool + LLM refinement.","metadata":{}},{"cell_type":"code","source":"# @title StrengthWeaknessAgent\n\nclass StrengthWeaknessAgent(Agent):\n    def __init__(self, model, strength_gap_tool, bullet_tool):\n        super().__init__(\n            name=\"StrengthWeaknessAgent\",\n            model=model,\n            instruction=\"\"\"\nYou are the Strength‚ÄìWeakness Evaluation Agent.\n\nYour job:\n1. Take web findings + conceptual knowledge explanation.\n2. Identify 5 strong points.\n3. Identify 5 weak points (gaps).\n4. Format them clearly.\n\"\"\",\n            tools=[strength_gap_tool, bullet_tool],\n            output_key=\"strength_weakness\",\n        )\n\n    async def run(self, combined_text: str):\n        heuristic = await self.tools[\"strength_gap_tool\"].call(\n            {\"text\": combined_text}\n        )\n\n        prompt = f\"\"\"\nRefine the following heuristic strengths/weaknesses.\n\nHEURISTIC:\n{heuristic}\n\nReturn exactly:\n- \"strengths\": 5 bullet points\n- \"weaknesses\": 5 bullet points\n\"\"\"\n        refined = await(self.model(prompt))\n\n        return {\"strengths_weaknesses\": refined}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.007732Z","iopub.execute_input":"2025-12-01T14:48:24.007988Z","iopub.status.idle":"2025-12-01T14:48:24.044090Z","shell.execute_reply.started":"2025-12-01T14:48:24.007972Z","shell.execute_reply":"2025-12-01T14:48:24.042608Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"### 6.5 Research Synthesizer Agent\n\nFinal merging agent ‚Äî similar to the aggregator agent in Day-1B.","metadata":{}},{"cell_type":"code","source":"# @title ResearchSynthesizerAgent\n\nclass ResearchSynthesizerAgent(Agent):\n    def __init__(self, model):\n        super().__init__(\n            name=\"ResearchSynthesizerAgent\",\n            model=model,\n            instruction=\"\"\"\nYou are a Research Synthesizer Agent.\n\nCombine:\n- Query understanding\n- Web research findings\n- Conceptual explanation\n- Strength‚Äìweakness analysis\n\nOutput a clean JSON with:\n- topic\n- conceptual_background\n- strong_points\n- weak_points\n- overall_summary (2‚Äì3 paragraphs)\n\"\"\",\n            output_key=\"final_report\",\n        )\n\n    async def run(self, pieces: dict):\n        prompt = f\"\"\"\nSYNTHESIZE THIS RESEARCH INFORMATION:\n\n{pieces}\n\nProduce a structured JSON object with:\n1. \"topic\"\n2. \"conceptual_background\"\n3. \"strong_points\"\n4. \"weak_points\"\n5. \"overall_summary\"\n\"\"\"\n        result = await self.model(prompt)\n        return {\"final_report\": result}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.045186Z","iopub.execute_input":"2025-12-01T14:48:24.045645Z","iopub.status.idle":"2025-12-01T14:48:24.085235Z","shell.execute_reply.started":"2025-12-01T14:48:24.045609Z","shell.execute_reply":"2025-12-01T14:48:24.083775Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# üìò SECTION 7 ‚Äî Root Orchestrator Agent\nA multi-step controller that governs the entire research pipeline","metadata":{}},{"cell_type":"markdown","source":"## üß† Section 7: Root Orchestrator Agent\n\nThis agent coordinates all other agents to produce the final research brief.\n\nWorkflow:\n1. Load session memory (Section 4)\n2. Run QueryUnderstandingAgent\n3. Run WebResearchAgent and KnowledgeExplainerAgent in parallel\n4. Combine outputs ‚Üí StrengthWeaknessAgent\n5. Merge all results ‚Üí ResearchSynthesizerAgent\n6. Save memory\n7. Return final structured report\n\nThis follows the multi-step orchestration patterns demonstrated in:\n- Day-1B (SequentialAgent, ParallelAgent)\n- Day-5A (Custom Orchestrators + Agent-to-Agent Messaging)\n- Day-5B (Realistic multi-agent flows)\n","metadata":{}},{"cell_type":"markdown","source":"### 7.1 Root Orchestrator Class","metadata":{}},{"cell_type":"code","source":"# @title Root Orchestrator Agent (FINAL FIX)\n\nfrom typing import Any\n\nclass RootResearchOrchestrator(Agent):\n    # 1. DECLARE FIELDS HERE so Pydantic allows them\n    query_agent: Any = None\n    web_agent: Any = None\n    explain_agent: Any = None\n    strength_agent: Any = None\n    synth_agent: Any = None\n    memory_manager: Any = None\n\n    def __init__(\n        self,\n        model,\n        query_agent,\n        web_agent,\n        explain_agent,\n        strength_agent,\n        synth_agent,\n        memory_manager,\n    ):\n        super().__init__(\n            name=\"RootResearchOrchestrator\",\n            model=model,\n            instruction=\"\"\"\nYou are the Root Research Orchestrator.\nYour goal is to coordinate the research agents to answer the user query.\n\"\"\",\n            output_key=\"orchestrator_output\",\n        )\n\n        # 2. Now you can assign them safely\n        self.query_agent = query_agent\n        self.web_agent = web_agent\n        self.explain_agent = explain_agent\n        self.strength_agent = strength_agent\n        self.synth_agent = synth_agent\n        self.memory_manager = memory_manager\n\n    async def run(self, user_query: str, session_id: str = None):\n        \n        # 1. Load Memory\n        session_state = session_service.get(session_id)\n        # Use the injected memory_manager\n        memory_items = self.memory_manager.load(session_state)\n        memory_summary = \"\\n\".join([m[\"content\"] for m in memory_items]) if memory_items else \"\"\n\n        # 2. Query Understanding\n        q_result = await self.query_agent.run(\n            user_query=user_query,\n            memory_summary=memory_summary,\n        )\n        topic = q_result.get(\"topic\", user_query)\n\n        # 3. Parallel Agents (Web + Explanation)\n        # We must await the tasks or gather them\n        web_task = asyncio.create_task(self.web_agent.run(topic))\n        explain_task = asyncio.create_task(self.explain_agent.run(topic))\n        \n        web_output, explain_output = await asyncio.gather(web_task, explain_task)\n\n        combined_text = (\n            f\"WEB FINDINGS:\\n{web_output}\\n\\n\"\n            f\"EXPLANATION:\\n{explain_output}\"\n        )\n\n        # 4. Strength & Weakness\n        sw_result = await self.strength_agent.run(combined_text)\n\n        # 5. Synthesis\n        pieces = {\n            \"query_understanding\": q_result,\n            \"web_research\": web_output,\n            \"conceptual_background\": explain_output,\n            \"strengths_and_weaknesses\": sw_result,\n        }\n\n        final_report = await self.synth_agent.run(pieces)\n\n        # 6. Save memory\n        # Note: In a notebook, 'add_memory_item' is global, which is fine.\n        await add_memory_item(\n            session_id,\n            {\"type\": \"research_turn\", \"content\": user_query},\n            llm_model=self.model,\n        )\n\n        return final_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.086934Z","iopub.execute_input":"2025-12-01T14:48:24.087418Z","iopub.status.idle":"2025-12-01T14:48:24.123962Z","shell.execute_reply.started":"2025-12-01T14:48:24.087400Z","shell.execute_reply":"2025-12-01T14:48:24.122976Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# üìò SECTION 8 ‚Äî Runner Setup\nConnecting the orchestrator to the ADK runtime","metadata":{}},{"cell_type":"code","source":"# @title Instantiate All Agents\n\n# Shared model configuration\nshared_model = Gemini(\n    model=\"gemini-2.5-flash\",\n    temperature=0.2,\n    max_output_tokens=2048,\n    retry_options=retry_config,\n)\n\n# Instantiate agents\nquery_agent = QueryUnderstandingAgent(model=shared_model)\n\nweb_agent = WebResearchAgent(\n    model=shared_model,\n    search_tool=SEARCH_TOOL,\n)\n\nexplain_agent = KnowledgeExplainerAgent(\n    model=shared_model\n)\n\nstrength_agent = StrengthWeaknessAgent(\n    model=shared_model,\n    strength_gap_tool=strength_gap_tool,\n    bullet_tool=bullet_tool\n)\n\n# strength_agent = StrengthWeaknessAgent(\n#     model=shared_model,\n#     web_findings_agent=web_agent,\n#     knowledge_explainer_agent=explain_agent\n# ) \n\nsynth_agent = ResearchSynthesizerAgent(\n    model=shared_model\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.124604Z","iopub.execute_input":"2025-12-01T14:48:24.124798Z","iopub.status.idle":"2025-12-01T14:48:24.141786Z","shell.execute_reply.started":"2025-12-01T14:48:24.124783Z","shell.execute_reply":"2025-12-01T14:48:24.140803Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## üèÉ Section 8: Runner Setup\n\nWe now create the ADK runner that executes the Root Orchestrator agent.\n\nThe ADK Runner:\n- Manages input/output flow\n- Tracks session state\n- Provides a unified interface for calling the agent system\n\nWe use `InMemoryRunner` for notebook testing, exactly as shown in Day-1B and Day-2A.\n","metadata":{}},{"cell_type":"markdown","source":"### 8.1 Instantiate All Agents\n\nHere, we wire together all agents built in Section 6.","metadata":{}},{"cell_type":"markdown","source":"### 8.2 Create the Root Orchestrator Agent","metadata":{}},{"cell_type":"code","source":"# @title Create Root Orchestrator Agent (CORRECTED)\n\n# Instantiate the orchestrator with all dependencies\nroot_orchestrator = RootResearchOrchestrator(\n    model=shared_model,\n    query_agent=query_agent,\n    web_agent=web_agent,\n    explain_agent=explain_agent,\n    strength_agent=strength_agent,\n    synth_agent=synth_agent,\n    memory_manager=memory_manager,\n)\n\nprint(\"Root Orchestrator initialized correctly with sub-agents.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.142863Z","iopub.execute_input":"2025-12-01T14:48:24.143065Z","iopub.status.idle":"2025-12-01T14:48:24.167623Z","shell.execute_reply.started":"2025-12-01T14:48:24.143042Z","shell.execute_reply":"2025-12-01T14:48:24.165873Z"}},"outputs":[{"name":"stdout","text":"Root Orchestrator initialized correctly with sub-agents.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"### 8.3 Create the ADK Runner\n\nThis matches the ADK usage pattern:\n\nrunner = InMemoryRunner(agent=root_agent)\n\n\nas seen in multiple daily notebooks (every Day-1B / Day-2 demo cell).","metadata":{}},{"cell_type":"code","source":"# @title Create InMemoryRunner\n\n# runner = InMemoryRunner(root_orchestrator)\n# print(\"InMemoryRunner is ready.\")\n\n\n# Define constants used throughout the notebook\nAPP_NAME = \"SRA_App\"\nUSER_ID = \"Emran\"\n\nmemory_service = (\n    InMemoryMemoryService()\n)\n\n# Create Session Service\nsession_service = InMemorySessionService()  # Handles conversations\n\n# Create runner with BOTH services\nrunner = Runner(\n    agent=root_orchestrator,\n    app_name=APP_NAME,\n    session_service=session_service,\n    memory_service=memory_service,  # Memory service is now available!\n)\n\nprint(\"‚úÖ Agent and Runner created with memory support!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.169245Z","iopub.execute_input":"2025-12-01T14:48:24.169555Z","iopub.status.idle":"2025-12-01T14:48:24.191204Z","shell.execute_reply.started":"2025-12-01T14:48:24.169535Z","shell.execute_reply":"2025-12-01T14:48:24.189806Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Agent and Runner created with memory support!\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# üìò SECTION 9 ‚Äî End-to-End Demo\nRun the entire multi-agent system with a real research query","metadata":{}},{"cell_type":"markdown","source":"## üß™ Section 9: End-to-End Demo\n\nThis section runs a full research request through the orchestrator using:\n- Query Understanding Agent\n- Parallel Web + Knowledge Agents\n- Strength‚ÄìWeakness Agent\n- Research Synthesizer Agent\n- Memory storage and compaction\n\nThe ADK `InMemoryRunner` will call our Root Orchestrator Agent.\n\nYou may modify the demo query below to test different topics.\n","metadata":{}},{"cell_type":"markdown","source":"### 9.1 Define a Demo Query","metadata":{}},{"cell_type":"code","source":"# @title Define a Demo Query\n\ndemo_query = \"Sleep disorder detection using multimodal physiological signals\"\n\nsession_id = \"demo-session-001\"   # Persistent session ID\nprint(\"Demo query ready:\", demo_query)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.192216Z","iopub.execute_input":"2025-12-01T14:48:24.192596Z","iopub.status.idle":"2025-12-01T14:48:24.219035Z","shell.execute_reply.started":"2025-12-01T14:48:24.192571Z","shell.execute_reply":"2025-12-01T14:48:24.218092Z"}},"outputs":[{"name":"stdout","text":"Demo query ready: Sleep disorder detection using multimodal physiological signals\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### 9.2 Run the Orchestrator via Runner\n\nThis matches the style used in:\n\nresult = runner.run(\"some input\")\n\n\nas seen in the daily notebooks.","metadata":{}},{"cell_type":"code","source":"# @title Run Full Research Pipeline\n\n\ninput_data = {\n    \"query\": demo_query,\n    \"session_id\": session_id,\n    \"query_agent\": query_agent,\n    \"web_agent\": web_agent,\n    \"explain_agent\": explain_agent,\n    \"strength_agent\": strength_agent,\n    \"synth_agent\": synth_agent,\n    \"session_id\": session_id, \n    \"memory_manager\": memory_manager,\n} \n\n\nresult = await run_session(runner, demo_query, session_id)\n\n\nprint(\"Pipeline executed successfully.\") \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:24.219949Z","iopub.execute_input":"2025-12-01T14:48:24.220235Z","iopub.status.idle":"2025-12-01T14:48:34.302913Z","shell.execute_reply.started":"2025-12-01T14:48:24.220214Z","shell.execute_reply":"2025-12-01T14:48:34.301293Z"}},"outputs":[{"name":"stdout","text":"\n### Session: demo-session-001\n\nUser > Sleep disorder detection using multimodal physiological signals\nModel: > Okay, Root Research Orchestrator here. The user wants to understand **\"Sleep disorder detection using multimodal physiological signals.\"** This is a broad but critical area of research. I need to break this down into actionable research tasks for my specialized agents to ensure comprehensive coverage.\n\nI will assign tasks focusing on current approaches, methodological details, specific applications, and data/ethical considerations.\n\n**Here are the initial research tasks:**\n\n1.  **Literature Reviewer (LR) Task:**\n    *   **Objective:** Provide a comprehensive overview of the current landscape and most commonly utilized multimodal physiological signals for sleep disorder detection. Identify key trends, recent breakthroughs, and influential studies in the last 5-7 years.\n    *   **Specific Questions:**\n        *   What are the primary physiological signals (e.g., EEG, EOG, EMG, ECG, PPG, SpO2, respiratory effort, actigraphy) commonly integrated for sleep disorder detection?\n        *   What are the most prevalent research directions and emerging technologies in this domain?\n        *   Identify and briefly describe 2-3 significant benchmark datasets used in this field.\n\n2.  **Methodology Expert (ME) Task:**\n    *   **Objective:** Detail the technical aspects, including signal processing, feature engineering, and the machine learning/deep learning architectures suitable for multimodal signal analysis in sleep disorder detection.\n    *   **Specific Questions:**\n        *   Describe typical signal processing pipelines for preparing different physiological signals (e.g., artifact removal, filtering, segmentation).\n        *   Discuss common feature extraction techniques applied to these signals for sleep staging and disorder detection.\n        *   Compare and contrast different multimodal fusion strategies (e.g., early, late, intermediate fusion) and their respective advantages/disadvantages in this context.\n        *   Highlight prominent machine learning (e.g., SVM, Random Forest) and deep learning (e.g., CNN, RNN, Transformers) architectures applied to multimodal sleep data.\n\n3.  **Application Specialist (AS) Task:**\n    *   **Objective:** Focus on the practical applications, specific sleep disorders addressed, clinical impact, and the role of wearable technology in this field.\n    *   **Specific Questions:**\n        *   For which specific sleep disorders (e.g., Obstructive Sleep Apnea (OSA), Insomnia, Narcolepsy, Restless Legs Syndrome (RLS), Periodic Limb Movement Disorder (PLMD)) has multimodal signal detection shown the most promise? Describe the typical signal patterns indicative of these disorders.\n        *   How do multimodal detection systems aim to improve upon traditional clinical diagnostic procedures (e.g., polysomnography (PSG))? What are the potential benefits for patients and healthcare systems?\n        *   Discuss the current role and future potential of wearable and home-based devices for multimodal sleep disorder detection.\n\n4.  **Data & Ethics Analyst (DEA) Task:**\n    *   **Objective:** Address the challenges related to data acquisition, annotation, availability, and the ethical implications of using physiological data for sleep disorder detection.\n    *   **Specific Questions:**\n        *   What are the major challenges in collecting, synchronizing, and annotating high-quality multimodal physiological sleep data?\n        *   Discuss the ethical considerations surrounding data privacy, security, consent, and potential biases (e.g., demographic, algorithmic) when developing and deploying AI-driven sleep disorder detection systems.\n        *   Are there significant limitations in current publicly available datasets regarding diversity, size, or annotation quality that hinder research progress?\n\nI will now send these tasks to the respective agents.\nPipeline executed successfully.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"### 9.3 View Final Report\n\nThis prints the orchestrator‚Äôs structured output.","metadata":{}},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:57.848273Z","iopub.execute_input":"2025-12-01T14:48:57.848563Z","iopub.status.idle":"2025-12-01T14:48:57.852728Z","shell.execute_reply.started":"2025-12-01T14:48:57.848545Z","shell.execute_reply":"2025-12-01T14:48:57.851516Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# @title View Final Report\n\nfrom pprint import pprint\n\nprint(\"\\n================ FINAL REPORT ================\\n\")\npprint(result[\"final_report\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:50:04.028248Z","iopub.execute_input":"2025-12-01T14:50:04.028609Z","iopub.status.idle":"2025-12-01T14:50:04.059120Z","shell.execute_reply.started":"2025-12-01T14:50:04.028592Z","shell.execute_reply":"2025-12-01T14:50:04.057845Z"}},"outputs":[{"name":"stdout","text":"\n================ FINAL REPORT ================\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_94/952959007.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n================ FINAL REPORT ================\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"final_report\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"],"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error"}],"execution_count":33},{"cell_type":"markdown","source":"### 9.4 View Session Memory After Execution\n\nThis demonstrates that memory was updated‚Äîjust like in the Day-3 memory notebooks.","metadata":{}},{"cell_type":"code","source":"# @title Memory Snapshot\n\nsession_state = session_service.get(session_id)\nmemory_after = session_state.get(\"memory\", [])\n\nprint(\"\\n================ SESSION MEMORY ================\\n\")\nfor i, item in enumerate(memory_after, 1):\n    print(f\"Memory Item {i}:\", item)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:50:09.644221Z","iopub.execute_input":"2025-12-01T14:50:09.644558Z","iopub.status.idle":"2025-12-01T14:50:09.667215Z","shell.execute_reply.started":"2025-12-01T14:50:09.644542Z","shell.execute_reply":"2025-12-01T14:50:09.665738Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_94/3914867620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Memory Snapshot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msession_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmemory_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'InMemorySessionService' object has no attribute 'get'"],"ename":"AttributeError","evalue":"'InMemorySessionService' object has no attribute 'get'","output_type":"error"}],"execution_count":34},{"cell_type":"markdown","source":"# üìò SECTION 10 ‚Äî JSON Mode Output & Formatting\nClean extraction, validation, and human-readable formatting of the final agent output","metadata":{}},{"cell_type":"markdown","source":"## üßæ Section 10: JSON Mode Output & Formatting\n\nThe final orchestrator output is an LLM-generated JSON-like structure.\nIn this section we:\n\n1. Extract JSON from the model output\n2. Validate and clean it\n3. Provide a \"pretty print\" text version\n4. Demonstrate the difference between raw machine output vs human-friendly rendering\n\nThis follows the output handling patterns shown in:\n- Day-4A (Observability & Logging)\n- Day-4B (Evaluation & Scoring)\n","metadata":{}},{"cell_type":"markdown","source":"### 10.1 Utility: Safe JSON Extraction\n\nLLM outputs sometimes contain leading/trailing commentary.\nThis utility mirrors the JSON cleanup/validation helpers from Day-4 notebooks.","metadata":{}},{"cell_type":"code","source":"# @title JSON Extraction Utility \n\ndef extract_json_block(text: str):\n    \"\"\"\n    Extracts the first JSON object found inside an LLM output,\n    with liberal cleanup rules similar to ADK Day-4 evaluation utilities.\n    \"\"\"\n    # Try strict load first\n    try:\n        return json.loads(text)\n    except:\n        pass\n\n    # Regex fallback ‚Äî extract braces\n    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n    if match:\n        candidate = match.group(0)\n        try:\n            return json.loads(candidate)\n        except:\n            pass\n\n    # Final fallback\n    return {\"error\": \"Could not parse JSON output\", \"raw_output\": text}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:34.447882Z","iopub.status.idle":"2025-12-01T14:48:34.448115Z","shell.execute_reply.started":"2025-12-01T14:48:34.448019Z","shell.execute_reply":"2025-12-01T14:48:34.448030Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10.2 Extract & Display Structured JSON\n\nWe take the output from Section 9 (result[\"final_report\"])\nand convert it into a validated Python dict.","metadata":{}},{"cell_type":"code","source":"# @title Extract JSON from Final Report\n\nraw_json_text = result.get(\"final_report\", \"\")\n\nclean_json = extract_json_block(raw_json_text)\n\nprint(\"======== CLEAN JSON OUTPUT ========\\n\")\nfrom pprint import pprint\npprint(clean_json)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:34.449030Z","iopub.status.idle":"2025-12-01T14:48:34.449226Z","shell.execute_reply.started":"2025-12-01T14:48:34.449122Z","shell.execute_reply":"2025-12-01T14:48:34.449132Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10.3 Pretty-Printed Human-Readable Summary\n\nThis creates a clean text summary from the JSON fields.","metadata":{}},{"cell_type":"code","source":"# @title Pretty Printed Summary\n\ndef pretty_print_research_summary(j):\n    if \"error\" in j:\n        print(\"‚ö†Ô∏è JSON error:\", j[\"error\"])\n        print(\"Raw output:\\n\", j.get(\"raw_output\", \"\"))\n        return\n    \n    topic = j.get(\"topic\", \"N/A\")\n    background = j.get(\"conceptual_background\", \"N/A\")\n    strengths = j.get(\"strong_points\", [])\n    weaknesses = j.get(\"weak_points\", [])\n    summary = j.get(\"overall_summary\", \"N/A\")\n\n    print(f\"# üß† Research Topic\\n{topic}\\n\")\n    print(\"## üìò Background\\n\", background, \"\\n\")\n\n    print(\"## üëç Strengths\")\n    for s in strengths:\n        print(\" -\", s)\n\n    print(\"\\n## ‚ö†Ô∏è Weaknesses / Gaps\")\n    for w in weaknesses:\n        print(\" -\", w)\n\n    print(\"\\n## üìù Final Summary\\n\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:34.451529Z","iopub.status.idle":"2025-12-01T14:48:34.451872Z","shell.execute_reply.started":"2025-12-01T14:48:34.451743Z","shell.execute_reply":"2025-12-01T14:48:34.451755Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10.4 Generate The Human-Readable Version","metadata":{}},{"cell_type":"code","source":"# @title Generate Research Summary\n\nprint(\"\\n======== HUMAN-READABLE RESEARCH SUMMARY ========\\n\")\npretty_print_research_summary(clean_json)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T14:48:34.453076Z","iopub.status.idle":"2025-12-01T14:48:34.453329Z","shell.execute_reply.started":"2025-12-01T14:48:34.453211Z","shell.execute_reply":"2025-12-01T14:48:34.453222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìò SECTION 11 ‚Äî Appendix & Troubleshooting\nAdditional notes, debugging guidance, and extension tips","metadata":{}},{"cell_type":"markdown","source":"## üìö Section 11: Appendix & Troubleshooting\n\nThis section provides references and troubleshooting instructions to help you\ndebug or extend the Smart Research Assistant. It mirrors the format used in the\nappendix sections of the ADK Day-4/Day-5 notebooks.\n","metadata":{}},{"cell_type":"markdown","source":"### üß© Issue: \"google_search\" returns empty results\nPossible causes:\n- Query too specific\n- DuckDuckGo/Google wrapper returns short or irrelevant entries\n- Upstream search engine throttling\n\nFixes:\n- Add more context words into the search query\n- Re-run the orchestrator to update cached results\n- Use broader phrasing (\"overview of ‚Ä¶\", \"recent research on ‚Ä¶\")\n","metadata":{}},{"cell_type":"markdown","source":"### üß© Issue: JSON extraction fails in Section 10\nLikely cause:\n- LLM returned natural language around the JSON\n- JSON contains trailing commas or stylistic variations\n\nFixes:\n- Use the JSON extraction helper to sanitize output\n- Add a stricter instruction in ResearchSynthesizerAgent\n- Reduce temperature for more deterministic output\n","metadata":{}},{"cell_type":"markdown","source":"### üß© Issue: Memory grows too large\nMemoryManager compaction may not be triggered if:\n- Too few memory items exist\n- Items contain very long text blocks\n\nFixes:\n- Reduce MAX_CONTEXT_TURNS or increase compaction frequency\n- Add custom logic to trim long content inside add_memory_item()\n","metadata":{}},{"cell_type":"markdown","source":"### 11.2 Debugging Agent Outputs","metadata":{}},{"cell_type":"markdown","source":"### üîç Tip: Print intermediate agent outputs\nInside the orchestrator, you can temporarily print:\n\nprint(\"Q-agent:\", q_result)\nprint(\"Web-findings:\", web_output)\nprint(\"Concept explain:\", explain_output)\n\nThis mirrors patterns used in Day-4 (Observability Tools) to debug pipelines.\n","metadata":{}},{"cell_type":"markdown","source":"### üîç Tip: Use verbose LLM logs\nYou can enable verbose logging of prompts/responses with:\n\nGemini(..., enable_prompt_logging=True)\n\nThis mirrors Day-4A where they show log-based observability.\n","metadata":{}},{"cell_type":"markdown","source":"### 11.3 Troubleshooting Parallel Execution\n\nFrom Day-5A (Agent-to-Agent Communication):","metadata":{}},{"cell_type":"markdown","source":"### ‚ö° If asyncio.gather hangs:\n- Check that both web_agent.run() and explain_agent.run() are async\n- Check if the google_search tool responded with a dict\n- Ensure no blocking code inside agents\n","metadata":{}},{"cell_type":"markdown","source":"### ‚ö° If one parallel agent fails:\nasyncio.gather(..., return_exceptions=True)\n\nUsing this pattern allows partial recovery without crashing the orchestrator.\n","metadata":{}},{"cell_type":"markdown","source":"### 11.4 Extending the System","metadata":{}},{"cell_type":"markdown","source":"### ‚ûï Add a Literature Review Agent\nUse:\n- google_search\n- summarization FunctionTool\n- a new LLM agent to synthesize multi-source findings\n","metadata":{}},{"cell_type":"markdown","source":"### ‚ûï Add a Citation Retrieval Agent\n- Wrap a scholarly search API into a FunctionTool\n- Query terms extracted by the QueryUnderstandingAgent\n","metadata":{}},{"cell_type":"markdown","source":"### ‚ûï Add Model-Based Observability\nImplement counters, timers, and JSON logs like Day-4A to inspect:\n- time per agent\n- token usage\n- intermediate trace output\n","metadata":{}},{"cell_type":"markdown","source":"### 11.5 Deployment Guidance (Day-5B Style)","metadata":{}},{"cell_type":"markdown","source":"### üö¢ Deployment Notes\nFor production use:\n1. Replace InMemoryRunner with a persistent session backend\n2. Use an MCP-hosted search tool for robust research queries\n3. Add retries/timeouts around all tool calls\n4. Consider splitting agents across worker processes for scalability\n","metadata":{}},{"cell_type":"markdown","source":"### üåê API Deployment\nUse:\n- Vertex AI Agent Runtime\n- A REST endpoint wrapping runner.run(...)\n- JSON input/output following Section 10\n\nThis mirrors the deployment examples in Day-5B.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}